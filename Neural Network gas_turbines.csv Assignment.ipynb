{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "815533d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80e43d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.70</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>114.71</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "      <td>3.5421</td>\n",
       "      <td>19.164</td>\n",
       "      <td>1049.7</td>\n",
       "      <td>546.21</td>\n",
       "      <td>111.61</td>\n",
       "      <td>10.400</td>\n",
       "      <td>4.5186</td>\n",
       "      <td>79.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "      <td>3.5059</td>\n",
       "      <td>19.414</td>\n",
       "      <td>1046.3</td>\n",
       "      <td>543.22</td>\n",
       "      <td>111.78</td>\n",
       "      <td>10.433</td>\n",
       "      <td>4.8470</td>\n",
       "      <td>79.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "      <td>3.4770</td>\n",
       "      <td>19.530</td>\n",
       "      <td>1037.7</td>\n",
       "      <td>537.32</td>\n",
       "      <td>110.19</td>\n",
       "      <td>10.483</td>\n",
       "      <td>7.9632</td>\n",
       "      <td>90.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "      <td>3.4486</td>\n",
       "      <td>19.377</td>\n",
       "      <td>1043.2</td>\n",
       "      <td>541.24</td>\n",
       "      <td>110.74</td>\n",
       "      <td>10.533</td>\n",
       "      <td>6.2494</td>\n",
       "      <td>93.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "      <td>3.4275</td>\n",
       "      <td>19.306</td>\n",
       "      <td>1049.9</td>\n",
       "      <td>545.85</td>\n",
       "      <td>111.58</td>\n",
       "      <td>10.583</td>\n",
       "      <td>4.9816</td>\n",
       "      <td>92.498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
       "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  114.70  10.605   \n",
       "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  114.72  10.598   \n",
       "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  114.71  10.601   \n",
       "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  114.72  10.606   \n",
       "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  114.72  10.612   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  111.61  10.400   \n",
       "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  111.78  10.433   \n",
       "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  110.19  10.483   \n",
       "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  110.74  10.533   \n",
       "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  111.58  10.583   \n",
       "\n",
       "           CO     NOX  \n",
       "0      3.1547  82.722  \n",
       "1      3.2363  82.776  \n",
       "2      3.2012  82.468  \n",
       "3      3.1923  82.670  \n",
       "4      3.2484  82.311  \n",
       "...       ...     ...  \n",
       "15034  4.5186  79.559  \n",
       "15035  4.8470  79.917  \n",
       "15036  7.9632  90.912  \n",
       "15037  6.2494  93.227  \n",
       "15038  4.9816  92.498  \n",
       "\n",
       "[15039 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"gas_turbines.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cbf26f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.iloc[:,[7,0,1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd9bf27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15039 entries, 0 to 15038\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   TEY     15039 non-null  float64\n",
      " 1   AT      15039 non-null  float64\n",
      " 2   AP      15039 non-null  float64\n",
      " 3   AH      15039 non-null  float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 470.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54b5be06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TEY    0\n",
       "AT     0\n",
       "AP     0\n",
       "AH     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da63312d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15039, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0084749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEY</th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.00000</td>\n",
       "      <td>15039.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>134.188464</td>\n",
       "      <td>17.764381</td>\n",
       "      <td>1013.19924</td>\n",
       "      <td>79.124174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.829717</td>\n",
       "      <td>7.574323</td>\n",
       "      <td>6.41076</td>\n",
       "      <td>13.793439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>100.170000</td>\n",
       "      <td>0.522300</td>\n",
       "      <td>985.85000</td>\n",
       "      <td>30.344000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>127.985000</td>\n",
       "      <td>11.408000</td>\n",
       "      <td>1008.90000</td>\n",
       "      <td>69.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>133.780000</td>\n",
       "      <td>18.186000</td>\n",
       "      <td>1012.80000</td>\n",
       "      <td>82.266000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>140.895000</td>\n",
       "      <td>23.862500</td>\n",
       "      <td>1016.90000</td>\n",
       "      <td>90.043500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>174.610000</td>\n",
       "      <td>34.929000</td>\n",
       "      <td>1034.20000</td>\n",
       "      <td>100.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                TEY            AT           AP            AH\n",
       "count  15039.000000  15039.000000  15039.00000  15039.000000\n",
       "mean     134.188464     17.764381   1013.19924     79.124174\n",
       "std       15.829717      7.574323      6.41076     13.793439\n",
       "min      100.170000      0.522300    985.85000     30.344000\n",
       "25%      127.985000     11.408000   1008.90000     69.750000\n",
       "50%      133.780000     18.186000   1012.80000     82.266000\n",
       "75%      140.895000     23.862500   1016.90000     90.043500\n",
       "max      174.610000     34.929000   1034.20000    100.200000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce66e315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH\n",
       "0      6.8594  1007.9  96.799\n",
       "1      6.7850  1008.4  97.118\n",
       "2      6.8977  1008.8  95.939\n",
       "3      7.0569  1009.2  95.249\n",
       "4      7.3978  1009.7  95.150\n",
       "...       ...     ...     ...\n",
       "15034  9.0301  1005.6  98.460\n",
       "15035  7.8879  1005.9  99.093\n",
       "15036  7.2647  1006.3  99.496\n",
       "15037  7.0060  1006.8  99.008\n",
       "15038  6.9279  1007.2  97.533\n",
       "\n",
       "[15039 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=df.iloc[:,1:5]\n",
    "y=df.iloc[:,0]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "341d0721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        114.70\n",
       "1        114.72\n",
       "2        114.71\n",
       "3        114.72\n",
       "4        114.72\n",
       "          ...  \n",
       "15034    111.61\n",
       "15035    111.78\n",
       "15036    110.19\n",
       "15037    110.74\n",
       "15038    111.58\n",
       "Name: TEY, Length: 15039, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dc4d1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/150\n",
      "WARNING:tensorflow:From C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1008/1008 [==============================] - 6s 4ms/step - loss: -2856440.2500 - accuracy: 0.0000e+00 - val_loss: -11081071.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -38372864.0000 - accuracy: 0.0000e+00 - val_loss: -75308408.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -142050656.0000 - accuracy: 0.0000e+00 - val_loss: -215905072.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -330262560.0000 - accuracy: 0.0000e+00 - val_loss: -444366560.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -613500288.0000 - accuracy: 0.0000e+00 - val_loss: -770291904.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -1001147072.0000 - accuracy: 0.0000e+00 - val_loss: -1202533248.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -1503159040.0000 - accuracy: 0.0000e+00 - val_loss: -1751704832.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -2129502592.0000 - accuracy: 0.0000e+00 - val_loss: -2426618368.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -2890335488.0000 - accuracy: 0.0000e+00 - val_loss: -3238257408.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -3795799040.0000 - accuracy: 0.0000e+00 - val_loss: -4195738624.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -4856621056.0000 - accuracy: 0.0000e+00 - val_loss: -5310107648.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -6082612224.0000 - accuracy: 0.0000e+00 - val_loss: -6590084096.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -7484167680.0000 - accuracy: 0.0000e+00 - val_loss: -8046908928.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -9071582208.0000 - accuracy: 0.0000e+00 - val_loss: -9689832448.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -10854277120.0000 - accuracy: 0.0000e+00 - val_loss: -11527866368.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -12843270144.0000 - accuracy: 0.0000e+00 - val_loss: -13572763648.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -15048152064.0000 - accuracy: 0.0000e+00 - val_loss: -15833306112.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/150\n",
      "1008/1008 [==============================] - 5s 5ms/step - loss: -17477992448.0000 - accuracy: 0.0000e+00 - val_loss: -18316273664.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -20142870528.0000 - accuracy: 0.0000e+00 - val_loss: -21035364352.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -23053576192.0000 - accuracy: 0.0000e+00 - val_loss: -23998269440.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -26219816960.0000 - accuracy: 0.0000e+00 - val_loss: -27216117760.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -29651124224.0000 - accuracy: 0.0000e+00 - val_loss: -30695888896.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -33358194688.0000 - accuracy: 0.0000e+00 - val_loss: -34451324928.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -37348900864.0000 - accuracy: 0.0000e+00 - val_loss: -38487302144.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -41634009088.0000 - accuracy: 0.0000e+00 - val_loss: -42815344640.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -46223642624.0000 - accuracy: 0.0000e+00 - val_loss: -47445274624.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -51127123968.0000 - accuracy: 0.0000e+00 - val_loss: -52386619392.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -56355061760.0000 - accuracy: 0.0000e+00 - val_loss: -57648259072.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -61913968640.0000 - accuracy: 0.0000e+00 - val_loss: -63237009408.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -67815100416.0000 - accuracy: 0.0000e+00 - val_loss: -69166276608.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -74072621056.0000 - accuracy: 0.0000e+00 - val_loss: -75449212928.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -80692191232.0000 - accuracy: 0.0000e+00 - val_loss: -82087051264.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -87680786432.0000 - accuracy: 0.0000e+00 - val_loss: -89089826816.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -95052177408.0000 - accuracy: 0.0000e+00 - val_loss: -96472891392.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -102813605888.0000 - accuracy: 0.0000e+00 - val_loss: -104239243264.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -110972870656.0000 - accuracy: 0.0000e+00 - val_loss: -112398155776.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -119543037952.0000 - accuracy: 0.0000e+00 - val_loss: -120964325376.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -128533987328.0000 - accuracy: 0.0000e+00 - val_loss: -129946353664.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -137955393536.0000 - accuracy: 0.0000e+00 - val_loss: -139351113728.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -147817447424.0000 - accuracy: 0.0000e+00 - val_loss: -149192130560.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -158125473792.0000 - accuracy: 0.0000e+00 - val_loss: -159470944256.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -168891957248.0000 - accuracy: 0.0000e+00 - val_loss: -170204364800.0000 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -180124991488.0000 - accuracy: 0.0000e+00 - val_loss: -181392670720.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -191833128960.0000 - accuracy: 0.0000e+00 - val_loss: -193056325632.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -204025397248.0000 - accuracy: 0.0000e+00 - val_loss: -205190545408.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -216714919936.0000 - accuracy: 0.0000e+00 - val_loss: -217818120192.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -229910298624.0000 - accuracy: 0.0000e+00 - val_loss: -230943145984.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -243619741696.0000 - accuracy: 0.0000e+00 - val_loss: -244577009664.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -257854521344.0000 - accuracy: 0.0000e+00 - val_loss: -258724773888.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -272623910912.0000 - accuracy: 0.0000e+00 - val_loss: -273401348096.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -287937495040.0000 - accuracy: 0.0000e+00 - val_loss: -288608518144.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -303800713216.0000 - accuracy: 0.0000e+00 - val_loss: -304359735296.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -320224165888.0000 - accuracy: 0.0000e+00 - val_loss: -320660701184.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/150\n",
      "1008/1008 [==============================] - 5s 5ms/step - loss: -337220075520.0000 - accuracy: 0.0000e+00 - val_loss: -337528422400.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -354802368512.0000 - accuracy: 0.0000e+00 - val_loss: -354976006144.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -372976746496.0000 - accuracy: 0.0000e+00 - val_loss: -372992966656.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -391742619648.0000 - accuracy: 0.0000e+00 - val_loss: -391601422336.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -411119157248.0000 - accuracy: 0.0000e+00 - val_loss: -410811269120.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -431113109504.0000 - accuracy: 0.0000e+00 - val_loss: -430621622272.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -451740368896.0000 - accuracy: 0.0000e+00 - val_loss: -451062726656.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -473008734208.0000 - accuracy: 0.0000e+00 - val_loss: -472126095360.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -494924005376.0000 - accuracy: 0.0000e+00 - val_loss: -493831618560.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -517491556352.0000 - accuracy: 0.0000e+00 - val_loss: -516168056832.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/150\n",
      "1008/1008 [==============================] - 5s 5ms/step - loss: -540718956544.0000 - accuracy: 0.0000e+00 - val_loss: -539161067520.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -564623114240.0000 - accuracy: 0.0000e+00 - val_loss: -562818711552.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -589215891456.0000 - accuracy: 0.0000e+00 - val_loss: -587153670144.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -614505840640.0000 - accuracy: 0.0000e+00 - val_loss: -612168826880.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -640485425152.0000 - accuracy: 0.0000e+00 - val_loss: -637861232640.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -667181580288.0000 - accuracy: 0.0000e+00 - val_loss: -664266342400.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -694606430208.0000 - accuracy: 0.0000e+00 - val_loss: -691384352768.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -722765938688.0000 - accuracy: 0.0000e+00 - val_loss: -719220178944.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -751661809664.0000 - accuracy: 0.0000e+00 - val_loss: -747774214144.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -781304332288.0000 - accuracy: 0.0000e+00 - val_loss: -777067626496.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -811696586752.0000 - accuracy: 0.0000e+00 - val_loss: -807092158464.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -842869637120.0000 - accuracy: 0.0000e+00 - val_loss: -837896503296.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -874819026944.0000 - accuracy: 0.0000e+00 - val_loss: -869450514432.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -907554455552.0000 - accuracy: 0.0000e+00 - val_loss: -901779488768.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -941087850496.0000 - accuracy: 0.0000e+00 - val_loss: -934889783296.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -975425830912.0000 - accuracy: 0.0000e+00 - val_loss: -968795095040.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -1010583732224.0000 - accuracy: 0.0000e+00 - val_loss: -1003498373120.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -1046559195136.0000 - accuracy: 0.0000e+00 - val_loss: -1039002959872.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -1083372863488.0000 - accuracy: 0.0000e+00 - val_loss: -1075337953280.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -1121035223040.0000 - accuracy: 0.0000e+00 - val_loss: -1112502173696.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -1159542603776.0000 - accuracy: 0.0000e+00 - val_loss: -1150495621120.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -1198922268672.0000 - accuracy: 0.0000e+00 - val_loss: -1189342478336.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -1239173955584.0000 - accuracy: 0.0000e+00 - val_loss: -1229051789312.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -1280311689216.0000 - accuracy: 0.0000e+00 - val_loss: -1269619490816.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -1322342809600.0000 - accuracy: 0.0000e+00 - val_loss: -1311066554368.0000 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -1365256175616.0000 - accuracy: 0.0000e+00 - val_loss: -1353376727040.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -1409080098816.0000 - accuracy: 0.0000e+00 - val_loss: -1396583563264.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -1453825064960.0000 - accuracy: 0.0000e+00 - val_loss: -1440702136320.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -1499493695488.0000 - accuracy: 0.0000e+00 - val_loss: -1485706362880.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -1546097786880.0000 - accuracy: 0.0000e+00 - val_loss: -1531658633216.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -1593656213504.0000 - accuracy: 0.0000e+00 - val_loss: -1578508484608.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -1642145775616.0000 - accuracy: 0.0000e+00 - val_loss: -1626290126848.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -1691613265920.0000 - accuracy: 0.0000e+00 - val_loss: -1675038031872.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -1742063009792.0000 - accuracy: 0.0000e+00 - val_loss: -1724756000768.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -1793506279424.0000 - accuracy: 0.0000e+00 - val_loss: -1775428042752.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -1845929705472.0000 - accuracy: 0.0000e+00 - val_loss: -1827060318208.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -1899370905600.0000 - accuracy: 0.0000e+00 - val_loss: -1879705649152.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -1953825816576.0000 - accuracy: 0.0000e+00 - val_loss: -1933338476544.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -2009265078272.0000 - accuracy: 0.0000e+00 - val_loss: -1987905847296.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -2065745575936.0000 - accuracy: 0.0000e+00 - val_loss: -2043555479552.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -2123289460736.0000 - accuracy: 0.0000e+00 - val_loss: -2100196147200.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -2181861343232.0000 - accuracy: 0.0000e+00 - val_loss: -2157865861120.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -2241507098624.0000 - accuracy: 0.0000e+00 - val_loss: -2216584544256.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -2302218600448.0000 - accuracy: 0.0000e+00 - val_loss: -2276337909760.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -2363992047616.0000 - accuracy: 0.0000e+00 - val_loss: -2337136705536.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -2426848673792.0000 - accuracy: 0.0000e+00 - val_loss: -2399016321024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -2490798964736.0000 - accuracy: 0.0000e+00 - val_loss: -2461935075328.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -2555859435520.0000 - accuracy: 0.0000e+00 - val_loss: -2525973446656.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -2622027988992.0000 - accuracy: 0.0000e+00 - val_loss: -2591083200512.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -2689325072384.0000 - accuracy: 0.0000e+00 - val_loss: -2657290289152.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/150\n",
      "1008/1008 [==============================] - 5s 5ms/step - loss: -2757767462912.0000 - accuracy: 0.0000e+00 - val_loss: -2724644519936.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -2827359879168.0000 - accuracy: 0.0000e+00 - val_loss: -2793107881984.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -2898090262528.0000 - accuracy: 0.0000e+00 - val_loss: -2862670675968.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -2969960710144.0000 - accuracy: 0.0000e+00 - val_loss: -2933356494848.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -3043023650816.0000 - accuracy: 0.0000e+00 - val_loss: -3005237428224.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -3117253918720.0000 - accuracy: 0.0000e+00 - val_loss: -3078241124352.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -3192671698944.0000 - accuracy: 0.0000e+00 - val_loss: -3152416604160.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -3269285904384.0000 - accuracy: 0.0000e+00 - val_loss: -3227746566144.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -3347102564352.0000 - accuracy: 0.0000e+00 - val_loss: -3304286846976.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -3426146844672.0000 - accuracy: 0.0000e+00 - val_loss: -3382013853696.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -3506434998272.0000 - accuracy: 0.0000e+00 - val_loss: -3460945936384.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -3587927703552.0000 - accuracy: 0.0000e+00 - val_loss: -3541055569920.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -3670667689984.0000 - accuracy: 0.0000e+00 - val_loss: -3622408028160.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -3754657316864.0000 - accuracy: 0.0000e+00 - val_loss: -3704947998720.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -3839904972800.0000 - accuracy: 0.0000e+00 - val_loss: -3788762251264.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -3926452076544.0000 - accuracy: 0.0000e+00 - val_loss: -3873844232192.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -4014268481536.0000 - accuracy: 0.0000e+00 - val_loss: -3960156717056.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -4103389315072.0000 - accuracy: 0.0000e+00 - val_loss: -4047742173184.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -4193778925568.0000 - accuracy: 0.0000e+00 - val_loss: -4136563638272.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -4285471916032.0000 - accuracy: 0.0000e+00 - val_loss: -4226677473280.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008/1008 [==============================] - 3s 3ms/step - loss: -4378493714432.0000 - accuracy: 0.0000e+00 - val_loss: -4318115921920.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -4472867127296.0000 - accuracy: 0.0000e+00 - val_loss: -4410830225408.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -4568552833024.0000 - accuracy: 0.0000e+00 - val_loss: -4504850268160.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -4665612173312.0000 - accuracy: 0.0000e+00 - val_loss: -4600217731072.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -4763991670784.0000 - accuracy: 0.0000e+00 - val_loss: -4696863408128.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -4863765774336.0000 - accuracy: 0.0000e+00 - val_loss: -4794883244032.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -4964885200896.0000 - accuracy: 0.0000e+00 - val_loss: -4894251548672.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -5067430690816.0000 - accuracy: 0.0000e+00 - val_loss: -4994966224896.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -5171344572416.0000 - accuracy: 0.0000e+00 - val_loss: -5097039331328.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -5276649390080.0000 - accuracy: 0.0000e+00 - val_loss: -5200461430784.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -5383380271104.0000 - accuracy: 0.0000e+00 - val_loss: -5305325846528.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -5491513622528.0000 - accuracy: 0.0000e+00 - val_loss: -5411518283776.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -5601075134464.0000 - accuracy: 0.0000e+00 - val_loss: -5519131017216.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/150\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: -5712087875584.0000 - accuracy: 0.0000e+00 - val_loss: -5628142026752.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -5824525107200.0000 - accuracy: 0.0000e+00 - val_loss: -5738535583744.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -5938400460800.0000 - accuracy: 0.0000e+00 - val_loss: -5850396098560.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/150\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: -6053787860992.0000 - accuracy: 0.0000e+00 - val_loss: -5963698405376.0000 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=3,  kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(8,  kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1,  kernel_initializer='uniform', activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history= model.fit(x, y,validation_split=0.33, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0669eb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/470 [==============================] - 1s 2ms/step - loss: -6063093972992.0000 - accuracy: 0.0000e+00\n",
      "accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x, y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d004b872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ad8e370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAksAAAHFCAYAAADi7703AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA7jUlEQVR4nO3de1xUdf7H8ffIZQDFUUFuhoCbqeQlhXK9LWqJ10yzNE3UtdwsS9HMa6VZK2lpVqRureW2XXRLbe1mYipZoqLiJSVty1sJqamAN67n90cP59cEHBHRYfD1fDzmsc73fM+Zzwdc5913zjljMQzDEAAAAEpUzdkFAAAAVGaEJQAAABOEJQAAABOEJQAAABOEJQAAABOEJQAAABOEJQAAABOEJQAAABOEJQAAABOEJQCV2sGDB2WxWLR48eLL3nf9+vWyWCxav359hdcF4PpBWAIAADBBWAIAF3P+/HnxtZ7AtUNYAmBq+vTpslgs2rVrl+69917ZbDbVqVNH48aNU0FBgfbt26du3brJ19dX4eHhmj17drFjHD58WIMHD1ZAQICsVquaNGmiOXPmqKioyGHe0aNH1b9/f/n6+spms2nAgAHKzMwssa6tW7eqd+/eqlOnjry8vNSyZUv95z//KVePx48f1yOPPKLIyEjVqFFDAQEB6ty5szZs2FBsbm5urmbMmKEmTZrIy8tLfn5+6tSpkzZu3GifU1RUpFdffVW33HKLvL29VatWLf35z3/WypUr7XMsFoumT59e7Pjh4eEaNmyY/fnixYtlsVi0evVqDR8+XHXr1pWPj49yc3P1v//9T3/961/VsGFD+fj4qF69errzzju1e/fuYsc9ffq0Hn/8cTVo0EBWq1UBAQHq0aOHvvvuOxmGoYYNG6pr167F9jtz5oxsNptGjRp1mT9VoOpwd3YBAFxD//79NXjwYD300ENKSkrS7NmzlZ+frzVr1uiRRx7R+PHj9d5772nixIm68cYbdffdd0v6LYi0bdtWeXl5evbZZxUeHq5PPvlE48eP1w8//KD58+dL+m215I477tDRo0eVkJCgm266SZ9++qkGDBhQrJZ169apW7duat26tRYuXCibzaYlS5ZowIABOnfunEPYKIuTJ09KkqZNm6agoCCdOXNGK1asUMeOHfXll1+qY8eOkqSCggJ1795dGzZsUHx8vDp37qyCggJt2rRJhw8fVtu2bSVJw4YN0zvvvKMHHnhAM2bMkKenp7Zv366DBw+W74cvafjw4erZs6f+/e9/6+zZs/Lw8NDRo0fl5+en559/XnXr1tXJkyf1r3/9S61bt1ZaWpoaNWokScrJyVH79u118OBBTZw4Ua1bt9aZM2f01VdfKSMjQ40bN9Zjjz2m+Ph4ff/992rYsKH9dd9++21lZ2cTlnB9MwDAxLRp0wxJxpw5cxzGb7nlFkOSsXz5cvtYfn6+UbduXePuu++2j02aNMmQZGzevNlh/4cfftiwWCzGvn37DMMwjAULFhiSjP/+978O80aMGGFIMt566y37WOPGjY2WLVsa+fn5DnN79eplBAcHG4WFhYZhGMa6desMSca6desuq+eCggIjPz/fuP32242+ffvax99++21DkvHGG2+Uuu9XX31lSDKmTp1q+hqSjGnTphUbDwsLM4YOHWp//tZbbxmSjCFDhpSp7ry8PKNhw4bG2LFj7eMzZswwJBlJSUml7pudnW34+voaY8aMcRiPjIw0OnXqdMnXBqoyPoYDUCa9evVyeN6kSRNZLBZ1797dPubu7q4bb7xRhw4dso+tXbtWkZGRuu222xz2HzZsmAzD0Nq1ayX9tlrk6+ur3r17O8wbNGiQw/P//e9/+u6773T//fdL+m215+KjR48eysjI0L59+y67v4ULF6pVq1by8vKSu7u7PDw89OWXXyo9Pd0+5/PPP5eXl5eGDx9e6nE+//xzSarwlZh+/foVGysoKNDMmTMVGRkpT09Pubu7y9PTU99//32xum+66SbdcccdpR7f19dXf/3rX7V48WKdPXtW0m+/u7179+rRRx+t0F4AV0NYAlAmderUcXju6ekpHx8feXl5FRu/cOGC/fmvv/6q4ODgYscLCQmxb7/4v4GBgcXmBQUFOTz/5ZdfJEnjx4+Xh4eHw+ORRx6RJJ04ceKyeps7d64efvhhtW7dWsuWLdOmTZuUmpqqbt266fz58/Z5x48fV0hIiKpVK/2fzuPHj8vNza1Y3VeqpJ/huHHj9NRTT6lPnz76+OOPtXnzZqWmpqpFixbF6r7hhhsu+RqPPfaYcnJy9O6770qSEhMTdcMNN+iuu+6quEYAF8Q5SwCuKj8/P2VkZBQbP3r0qCTJ39/fPm/Lli3F5v3xBO+L8ydPnmw/L+qPLp6rU1bvvPOOOnbsqAULFjiM5+TkODyvW7euvv76axUVFZUamOrWravCwkJlZmaWGHAuslqtys3NLTZ+MTz+kcViKbHuIUOGaObMmQ7jJ06cUK1atRxq+umnn0qt5aIbb7xR3bt312uvvabu3btr5cqVeuaZZ+Tm5nbJfYGqjJUlAFfV7bffrr1792r79u0O42+//bYsFos6deokSerUqZNycnIcrhiTpPfee8/heaNGjdSwYUPt3LlT0dHRJT58fX0vq0aLxSKr1eowtmvXLqWkpDiMde/eXRcuXDC9QebFjyX/GLz+KDw8XLt27XIYW7t2rc6cOXNFdX/66af6+eefi9W0f/9++0eeZsaMGaNdu3Zp6NChcnNz04gRI8pcD1BVsbIE4KoaO3as3n77bfXs2VMzZsxQWFiYPv30U82fP18PP/ywbrrpJknSkCFD9NJLL2nIkCH6+9//roYNG+qzzz7TF198UeyY//jHP9S9e3d17dpVw4YNU7169XTy5Emlp6dr+/bt+uCDDy6rxl69eunZZ5/VtGnTFBMTo3379mnGjBmKiIhQQUGBfd7AgQP11ltvaeTIkdq3b586deqkoqIibd68WU2aNNF9992nDh06KC4uTs8995x++eUX9erVS1arVWlpafLx8dFjjz0mSYqLi9NTTz2lp59+WjExMdq7d68SExNls9kuq+7FixercePGat68ubZt26YXXnih2Edu8fHxWrp0qe666y5NmjRJt912m86fP6/k5GT16tXLHlglqUuXLoqMjNS6devst3sArnvOPsMcQOV28Wq448ePO4wPHTrUqF69erH5MTExxs033+wwdujQIWPQoEGGn5+f4eHhYTRq1Mh44YUX7FetXfTTTz8Z/fr1M2rUqGH4+voa/fr1MzZu3FjsajjDMIydO3ca/fv3NwICAgwPDw8jKCjI6Ny5s7Fw4UL7nLJeDZebm2uMHz/eqFevnuHl5WW0atXK+Oijj4yhQ4caYWFhDnPPnz9vPP3000bDhg0NT09Pw8/Pz+jcubOxceNG+5zCwkLjpZdeMpo2bWp4enoaNpvNaNOmjfHxxx87vOaECROM0NBQw9vb24iJiTF27NhR6tVwqampxeo+deqU8cADDxgBAQGGj4+P0b59e2PDhg1GTEyMERMTU2zumDFjjPr16xseHh5GQECA0bNnT+O7774rdtzp06cbkoxNmzaZ/tyA64XFMLgNLADg/0VHR8tisSg1NdXZpQCVAh/DAQCUnZ2tb7/9Vp988om2bdumFStWOLskoNIgLAEAtH37dnXq1El+fn6aNm2a+vTp4+ySgEqDj+EAAABMcOsAAAAAE4QlAAAAE4QlAAAAE5zgXQGKiop09OhR+fr6lviVBAAAoPIxDEM5OTmX/M5HwlIFOHr0qEJDQ51dBgAAKIcjR46Yftk0YakCXPweqiNHjqhmzZpOrgYAAJRFdna2QkNDL/l9koSlCnDxo7eaNWsSlgAAcDGXOoWGE7wBAABMEJYAAABMEJYAAABMcM7SNVRYWKj8/Hxnl+GSPD09TS/rBADgaiEsXQOGYSgzM1OnT592dikuq1q1aoqIiJCnp6ezSwEAXGcIS9fAxaAUEBAgHx8fblx5mS7e9DMjI0P169fn5wcAuKYIS1dZYWGhPSj5+fk5uxyXVbduXR09elQFBQXy8PBwdjkAgOsIJ4FcZRfPUfLx8XFyJa7t4sdvhYWFTq4EAHC9ISxdI3x0dGX4+QEAnIWwBAAAYIKwhGsiPDxc8+bNc3YZAABcNk7wRqk6duyoW265pUJCTmpqqqpXr37lRQEAcI0RllBuhmGosLBQ7u6X/mtUt27da1ARAAAVj4/hUKJhw4YpOTlZL7/8siwWiywWixYvXiyLxaIvvvhC0dHRslqt2rBhg3744QfdddddCgwMVI0aNXTrrbdqzZo1Dsf748dwFotF//znP9W3b1/5+PioYcOGWrly5TXuEgCASyMsXWOGYehcXoFTHoZhlLnOl19+WW3atNGIESOUkZGhjIwMhYaGSpImTJighIQEpaenq3nz5jpz5ox69OihNWvWKC0tTV27dtWdd96pw4cPm77GM888o/79+2vXrl3q0aOH7r//fp08efKKfr4AAFQ0Poa7xs7nFyry6S+c8tp7Z3SVj2fZfuU2m02enp7y8fFRUFCQJOm7776TJM2YMUNdunSxz/Xz81OLFi3sz5977jmtWLFCK1eu1KOPPlrqawwbNkwDBw6UJM2cOVOvvvqqtmzZom7dul12bwAAXC2sLOGyRUdHOzw/e/asJkyYoMjISNWqVUs1atTQd999d8mVpebNm9v/XL16dfn6+urYsWNXpWYAAMqLlaVrzNvDTXtndHXaa1eEP17V9sQTT+iLL77Qiy++qBtvvFHe3t665557lJeXZ3qcP35ticViUVFRUYXUCABARSEsXWMWi6XMH4U5m6enZ5m+XmTDhg0aNmyY+vbtK0k6c+aMDh48eJWrAwDg2uBjOJQqPDxcmzdv1sGDB3XixIlSV31uvPFGLV++XDt27NDOnTs1aNAgVogAAFUGYQmlGj9+vNzc3BQZGam6deuWeg7SSy+9pNq1a6tt27a688471bVrV7Vq1eoaVwsAwNVhMS7nenKUKDs7WzabTVlZWapZs6bDtgsXLujAgQOKiIiQl5eXkyp0ffwcAQAVzez9+/dYWQIAADBBWAIAADBBWAIAADBBWAIAADBBWAIAADBBWAIAADBBWAIAADBBWAIAADBBWAIAADBBWAIAADBBWEKpOnbsqPj4+Ao73rBhw9SnT58KOx4AANcCYQkAAMAEYQklGjZsmJKTk/Xyyy/LYrHIYrHo4MGD2rt3r3r06KEaNWooMDBQcXFxOnHihH2/Dz/8UM2aNZO3t7f8/Px0xx136OzZs5o+fbr+9a9/6b///a/9eOvXr3degwAAlJG7swu47hiGlH/OOa/t4SNZLGWa+vLLL2v//v1q2rSpZsyYIUkqLCxUTEyMRowYoblz5+r8+fOaOHGi+vfvr7Vr1yojI0MDBw7U7Nmz1bdvX+Xk5GjDhg0yDEPjx49Xenq6srOz9dZbb0mS6tSpc9VaBQCgohCWrrX8c9LMEOe89pSjkmf1Mk212Wzy9PSUj4+PgoKCJElPP/20WrVqpZkzZ9rnvfnmmwoNDdX+/ft15swZFRQU6O6771ZYWJgkqVmzZva53t7eys3NtR8PAABXQFhCmW3btk3r1q1TjRo1im374YcfFBsbq9tvv13NmjVT165dFRsbq3vuuUe1a9d2QrUAAFQMwtK15uHz2wqPs177ChQVFenOO+/UrFmzim0LDg6Wm5ubkpKStHHjRq1evVqvvvqqpk6dqs2bNysiIuKKXhsAAGchLF1rFkuZPwpzNk9PTxUWFtqft2rVSsuWLVN4eLjc3Uv+q2OxWNSuXTu1a9dOTz/9tMLCwrRixQqNGzeu2PEAAHAFXA2HUoWHh2vz5s06ePCgTpw4oVGjRunkyZMaOHCgtmzZoh9//FGrV6/W8OHDVVhYqM2bN2vmzJnaunWrDh8+rOXLl+v48eNq0qSJ/Xi7du3Svn37dOLECeXn5zu5QwAALo2whFKNHz9ebm5uioyMVN26dZWXl6dvvvlGhYWF6tq1q5o2baoxY8bIZrOpWrVqqlmzpr766iv16NFDN910k5588knNmTNH3bt3lySNGDFCjRo1UnR0tOrWratvvvnGyR0CAHBpFsMwDGcX4eqys7Nls9mUlZWlmjVrOmy7cOGCDhw4oIiICHl5eTmpQtfHzxEAUNHM3r9/z+VWlubPn29/w4yKitKGDRtM5ycnJysqKkpeXl5q0KCBFi5cWOrcJUuWyGKx8JUcAADAzqXC0tKlSxUfH6+pU6cqLS1NHTp0UPfu3XX48OES5x84cEA9evRQhw4dlJaWpilTpmj06NFatmxZsbmHDh3S+PHj1aFDh6vdBgAAcCEuFZbmzp2rBx54QA8++KCaNGmiefPmKTQ0VAsWLChx/sKFC1W/fn3NmzdPTZo00YMPPqjhw4frxRdfdJhXWFio+++/X88884waNGhwLVoBAAAuwmXCUl5enrZt26bY2FiH8djYWG3cuLHEfVJSUorN79q1q7Zu3epwJdaMGTNUt25dPfDAAxVfOAAAcGkuc5+lEydOqLCwUIGBgQ7jgYGByszMLHGfzMzMEucXFBToxIkTCg4O1jfffKNFixZpx44dZa4lNzdXubm59ufZ2dmX3Ifz6K8MPz8AgLO4zMrSRZY/fBGsYRjFxi41/+J4Tk6OBg8erDfeeEP+/v5lriEhIUE2m83+CA0NLXWuh4eHJOncOSd9eW4VkZeXJ0lyc3NzciUAgOuNy6ws+fv7y83Nrdgq0rFjx4qtHl0UFBRU4nx3d3f5+flpz549OnjwoO6880779qKiIkmSu7u79u3bpz/96U/Fjjt58mSNGzfO/jw7O7vUwOTm5qZatWrp2LFjkiQfHx/TcIfiioqKdPz4cfn4+JR653AAAK4Wl3nn8fT0VFRUlJKSktS3b1/7eFJSku66664S92nTpo0+/vhjh7HVq1crOjpaHh4eaty4sXbv3u2w/cknn1ROTo5efvnlUgOQ1WqV1Wotc+1BQUGSZA9MuHzVqlVT/fr1CZoAgGvOZcKSJI0bN05xcXGKjo5WmzZt9Prrr+vw4cMaOXKkpN9WfH7++We9/fbbkqSRI0cqMTFR48aN04gRI5SSkqJFixbp/ffflyR5eXmpadOmDq9Rq1YtSSo2fiUsFouCg4MVEBDAV3yUk6enp6pVc7lPjQEAVYBLhaUBAwbo119/1YwZM5SRkaGmTZvqs88+U1hYmCQpIyPD4Z5LERER+uyzzzR27Fi99tprCgkJ0SuvvKJ+/fo5pX43NzfOuQEAwMXwdScVoKy3SwcAAJVHlf26EwAAgGuJsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGCCsAQAAGDC5cLS/PnzFRERIS8vL0VFRWnDhg2m85OTkxUVFSUvLy81aNBACxcudNj+xhtvqEOHDqpdu7Zq166tO+64Q1u2bLmaLQAAABfiUmFp6dKlio+P19SpU5WWlqYOHTqoe/fuOnz4cInzDxw4oB49eqhDhw5KS0vTlClTNHr0aC1btsw+Z/369Ro4cKDWrVunlJQU1a9fX7Gxsfr555+vVVsAAKASsxiGYTi7iLJq3bq1WrVqpQULFtjHmjRpoj59+ighIaHY/IkTJ2rlypVKT0+3j40cOVI7d+5USkpKia9RWFio2rVrKzExUUOGDClTXdnZ2bLZbMrKylLNmjUvsysAAOAMZX3/dpmVpby8PG3btk2xsbEO47Gxsdq4cWOJ+6SkpBSb37VrV23dulX5+fkl7nPu3Dnl5+erTp06FVM4AABwae7OLqCsTpw4ocLCQgUGBjqMBwYGKjMzs8R9MjMzS5xfUFCgEydOKDg4uNg+kyZNUr169XTHHXeUWktubq5yc3Ptz7Ozsy+nFQAA4EJcZmXpIovF4vDcMIxiY5eaX9K4JM2ePVvvv/++li9fLi8vr1KPmZCQIJvNZn+EhoZeTgsAAMCFuExY8vf3l5ubW7FVpGPHjhVbPbooKCioxPnu7u7y8/NzGH/xxRc1c+ZMrV69Ws2bNzetZfLkycrKyrI/jhw5Uo6OAACAK3CZsOTp6amoqCglJSU5jCclJalt27Yl7tOmTZti81evXq3o6Gh5eHjYx1544QU9++yzWrVqlaKjoy9Zi9VqVc2aNR0eAACganKZsCRJ48aN0z//+U+9+eabSk9P19ixY3X48GGNHDlS0m8rPr+/gm3kyJE6dOiQxo0bp/T0dL355ptatGiRxo8fb58ze/ZsPfnkk3rzzTcVHh6uzMxMZWZm6syZM9e8PwAAUPm4zAnekjRgwAD9+uuvmjFjhjIyMtS0aVN99tlnCgsLkyRlZGQ43HMpIiJCn332mcaOHavXXntNISEheuWVV9SvXz/7nPnz5ysvL0/33HOPw2tNmzZN06dPvyZ9AQCAysul7rNUWXGfJQAAXE+Vu88SAACAMxCWAAAATBCWAAAATBCWAAAATBCWAAAATBCWAAAATBCWAAAATBCWAAAATBCWAAAATBCWAAAATBCWAAAATBCWAAAATBCWAAAATBCWAAAATBCWAAAATBCWAAAATBCWAAAATBCWAAAATBCWAAAATBCWAAAATBCWAAAATBCWAAAATBCWAAAATBCWAAAATBCWAAAATBCWAAAATBCWAAAATBCWAAAATBCWAAAATBCWAAAATBCWAAAATBCWAAAATJQrLK1fv76CywAAAKicyhWWunXrpj/96U967rnndOTIkYquCQAAoNIoV1g6evSoxowZo+XLlysiIkJdu3bVf/7zH+Xl5VV0fQAAAE5VrrBUp04djR49Wtu3b9fWrVvVqFEjjRo1SsHBwRo9erR27txZ0XUCAAA4xRWf4H3LLbdo0qRJGjVqlM6ePas333xTUVFR6tChg/bs2VMRNQIAADhNucNSfn6+PvzwQ/Xo0UNhYWH64osvlJiYqF9++UUHDhxQaGio7r333oqsFQAA4JpzL89Ojz32mN5//31J0uDBgzV79mw1bdrUvr169ep6/vnnFR4eXiFFAgAAOEu5wtLevXv16quvql+/fvL09CxxTkhIiNatW3dFxQEAADibxTAMw9lFuLrs7GzZbDZlZWWpZs2azi4HAACUQVnfv8t1zlJCQoLefPPNYuNvvvmmZs2aVZ5DAgAAVErlCkv/+Mc/1Lhx42LjN998sxYuXHjFRQEAAFQW5QpLmZmZCg4OLjZet25dZWRkXHFRAAAAlUW5wlJoaKi++eabYuPffPONQkJCrrgoAACAyqJcV8M9+OCDio+PV35+vjp37ixJ+vLLLzVhwgQ9/vjjFVogAACAM5UrLE2YMEEnT57UI488Yv8+OC8vL02cOFGTJ0+u0AIBAACc6YpuHXDmzBmlp6fL29tbDRs2lNVqrcjaXAa3DgAAwPWU9f27XCtLF9WoUUO33nrrlRwCAACgUit3WEpNTdUHH3ygw4cP2z+Ku2j58uVXXBgAAEBlUK6r4ZYsWaJ27dpp7969WrFihfLz87V3716tXbtWNputomsEAABwmnKFpZkzZ+qll17SJ598Ik9PT7388stKT09X//79Vb9+/YquEQAAwGnKFZZ++OEH9ezZU5JktVp19uxZWSwWjR07Vq+//nqFFggAAOBM5QpLderUUU5OjiSpXr16+vbbbyVJp0+f1rlz5yquOgAAACcr1wneHTp0UFJSkpo1a6b+/ftrzJgxWrt2rZKSknT77bdXdI0AAABOU66wlJiYqAsXLkiSJk+eLA8PD3399de6++679dRTT1VogQAAAM502TelLCgo0LvvvquuXbsqKCjoatXlUrgpJQAArqes79+Xfc6Su7u7Hn74YeXm5l5RgeU1f/58RUREyMvLS1FRUdqwYYPp/OTkZEVFRcnLy0sNGjTQwoULi81ZtmyZIiMjZbVaFRkZqRUrVlyt8gEAgIsp1wnerVu3VlpaWkXXcklLly5VfHy8pk6dqrS0NHXo0EHdu3fX4cOHS5x/4MAB9ejRQx06dFBaWpqmTJmi0aNHa9myZfY5KSkpGjBggOLi4rRz507FxcWpf//+2rx587VqCwAAVGLl+m64Dz74QJMmTdLYsWMVFRWl6tWrO2xv3rx5hRX4e61bt1arVq20YMEC+1iTJk3Up08fJSQkFJs/ceJErVy5Uunp6faxkSNHaufOnUpJSZEkDRgwQNnZ2fr888/tc7p166batWvr/fffL1NdV+NjOKOoSOfP5VTIsQAAcHXePr6yVCvXGk+prup3ww0YMECSNHr0aPuYxWKRYRiyWCwqLCwsz2FN5eXladu2bZo0aZLDeGxsrDZu3FjiPikpKYqNjXUY69q1qxYtWqT8/Hx5eHgoJSVFY8eOLTZn3rx5pdaSm5vr8DFkdnb2ZXZzaefP5cjnRW7wCQCAJJ0bf1g+NZzzLSHlCksHDhyo6Dou6cSJEyosLFRgYKDDeGBgoDIzM0vcJzMzs8T5BQUFOnHihIKDg0udU9oxJSkhIUHPPPNMOTsBAACupFxhKSwsrKLrKDOLxeLw/OJq1uXM/+P45R5z8uTJGjdunP15dna2QkNDL138ZfD28dW58SWfiwUAwPXG28fXaa9drrD09ttvm24fMmRIuYox4+/vLzc3t2IrPseOHSu2MnRRUFBQifPd3d3l5+dnOqe0Y0q/fcWL1WotTxtlZqlWzWnLjQAA4P+VKyyNGTPG4Xl+fr7OnTsnT09P+fj4XJWw5OnpqaioKCUlJalv37728aSkJN11110l7tOmTRt9/PHHDmOrV69WdHS0PDw87HOSkpIczltavXq12rZtW+E9AAAA11OusHTq1KliY99//70efvhhPfHEE1dcVGnGjRunuLg4RUdHq02bNnr99dd1+PBhjRw5UtJvH4/9/PPP9pWvkSNHKjExUePGjdOIESOUkpKiRYsWOVzlNmbMGP3lL3/RrFmzdNddd+m///2v1qxZo6+//vqq9QEAAFyIUYFSU1ONRo0aVeQhi3nttdeMsLAww9PT02jVqpWRnJxs3zZ06FAjJibGYf769euNli1bGp6enkZ4eLixYMGCYsf84IMPjEaNGhkeHh5G48aNjWXLll1WTVlZWYYkIysrq1w9AQCAa6+s79/lus9SadLS0hQTE3NVLqWvzPi6EwAAXM9Vvc/SypUrHZ4bhqGMjAwlJiaqXbt25TkkAABApVSusNSnTx+H5xaLRXXr1lXnzp01Z86ciqgLAACgUihXWCoqKqroOgAAACqliv2SFQAAgCqmXGHpnnvu0fPPP19s/IUXXtC99957xUUBAABUFuUKS8nJyerZs2ex8W7duumrr7664qIAAAAqi3KFpTNnzsjT07PYuIeHx3V32wAAAFC1lSssNW3aVEuXLi02vmTJEkVGRl5xUQAAAJVFua6Ge+qpp9SvXz/98MMP6ty5syTpyy+/1Pvvv68PPvigQgsEAABwpnKFpd69e+ujjz7SzJkz9eGHH8rb21vNmzfXmjVrFBMTU9E1AgAAOE2Fft3J9YqvOwEAwPWU9f27XOcspaamavPmzcXGN2/erK1bt5bnkAAAAJVSucLSqFGjdOTIkWLjP//8s0aNGnXFRQEAAFQW5QpLe/fuVatWrYqNt2zZUnv37r3iogAAACqLcoUlq9WqX375pdh4RkaG3N3Ldc44AABApVSusNSlSxdNnjxZWVlZ9rHTp09rypQp6tKlS4UVBwAA4GzlWgaaM2eO/vKXvygsLEwtW7aUJO3YsUOBgYH697//XaEFAgAAOFO5wlK9evW0a9cuvfvuu9q5c6e8vb3117/+VQMHDpSHh0dF1wgAAOA05T7BqHr16mrfvr3q16+vvLw8SdLnn38u6bebVgIAAFQF5QpLP/74o/r27avdu3fLYrHIMAxZLBb79sLCwgorEAAAwJnKdYL3mDFjFBERoV9++UU+Pj769ttvlZycrOjoaK1fv76CSwQAAHCecq0spaSkaO3atapbt66qVasmNzc3tW/fXgkJCRo9erTS0tIquk4AAACnKNfKUmFhoWrUqCFJ8vf319GjRyVJYWFh2rdvX8VVBwAA4GTlWllq2rSpdu3apQYNGqh169aaPXu2PD099frrr6tBgwYVXSMAAIDTlCssPfnkkzp79qwk6bnnnlOvXr3UoUMH+fn5aenSpRVaIAAAgDNZDMMwKuJAJ0+eVO3atR2uirteZGdny2azKSsrSzVr1nR2OQAAoAzK+v5dYV/kVqdOnYo6FAAAQKVRrhO8AQAArheEJQAAABOEJQAAABOEJQAAABOEJQAAABOEJQAAABOEJQAAABOEJQAAABOEJQAAABOEJQAAABOEJQAAABOEJQAAABOEJQAAABOEJQAAABOEJQAAABOEJQAAABOEJQAAABOEJQAAABOEJQAAABOEJQAAABOEJQAAABOEJQAAABOEJQAAABOEJQAAABOEJQAAABOEJQAAABOEJQAAABOEJQAAABOEJQAAABMuE5ZOnTqluLg42Ww22Ww2xcXF6fTp06b7GIah6dOnKyQkRN7e3urYsaP27Nlj337y5Ek99thjatSokXx8fFS/fn2NHj1aWVlZV7kbAADgKlwmLA0aNEg7duzQqlWrtGrVKu3YsUNxcXGm+8yePVtz585VYmKiUlNTFRQUpC5duignJ0eSdPToUR09elQvvviidu/ercWLF2vVqlV64IEHrkVLAADABVgMwzCcXcSlpKenKzIyUps2bVLr1q0lSZs2bVKbNm303XffqVGjRsX2MQxDISEhio+P18SJEyVJubm5CgwM1KxZs/TQQw+V+FoffPCBBg8erLNnz8rd3b1M9WVnZ8tmsykrK0s1a9YsZ5cAAOBaKuv7t0usLKWkpMhms9mDkiT9+c9/ls1m08aNG0vc58CBA8rMzFRsbKx9zGq1KiYmptR9JNl/YGZBKTc3V9nZ2Q4PAABQNblEWMrMzFRAQECx8YCAAGVmZpa6jyQFBgY6jAcGBpa6z6+//qpnn3221FWnixISEuznTtlsNoWGhpalDQAA4IKcGpamT58ui8Vi+ti6daskyWKxFNvfMIwSx3/vj9tL2yc7O1s9e/ZUZGSkpk2bZnrMyZMnKysry/44cuTIpVoFAAAuqmwn5Vwljz76qO677z7TOeHh4dq1a5d++eWXYtuOHz9ebOXooqCgIEm/rTAFBwfbx48dO1Zsn5ycHHXr1k01atTQihUr5OHhYVqT1WqV1Wo1nQMAAKoGp4Ylf39/+fv7X3JemzZtlJWVpS1btui2226TJG3evFlZWVlq27ZtiftEREQoKChISUlJatmypSQpLy9PycnJmjVrln1edna2unbtKqvVqpUrV8rLy6sCOgMAAFWFS5yz1KRJE3Xr1k0jRozQpk2btGnTJo0YMUK9evVyuBKucePGWrFihaTfPn6Lj4/XzJkztWLFCn377bcaNmyYfHx8NGjQIEm/rSjFxsbq7NmzWrRokbKzs5WZmanMzEwVFhY6pVcAAFC5OHVl6XK8++67Gj16tP3qtt69eysxMdFhzr59+xxuKDlhwgSdP39ejzzyiE6dOqXWrVtr9erV8vX1lSRt27ZNmzdvliTdeOONDsc6cOCAwsPDr2JHAADAFbjEfZYqO+6zBACA66lS91kCAABwFsISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACcISAACACZcJS6dOnVJcXJxsNptsNpvi4uJ0+vRp030Mw9D06dMVEhIib29vdezYUXv27Cl1bvfu3WWxWPTRRx9VfAMAAMAluUxYGjRokHbs2KFVq1Zp1apV2rFjh+Li4kz3mT17tubOnavExESlpqYqKChIXbp0UU5OTrG58+bNk8ViuVrlAwAAF+Xu7ALKIj09XatWrdKmTZvUunVrSdIbb7yhNm3aaN++fWrUqFGxfQzD0Lx58zR16lTdfffdkqR//etfCgwM1HvvvaeHHnrIPnfnzp2aO3euUlNTFRwcfG2aAgAALsElVpZSUlJks9nsQUmS/vznP8tms2njxo0l7nPgwAFlZmYqNjbWPma1WhUTE+Owz7lz5zRw4EAlJiYqKCioTPXk5uYqOzvb4QEAAKomlwhLmZmZCggIKDYeEBCgzMzMUveRpMDAQIfxwMBAh33Gjh2rtm3b6q677ipzPQkJCfZzp2w2m0JDQ8u8LwAAcC1ODUvTp0+XxWIxfWzdulWSSjyfyDCMS55n9Mftv99n5cqVWrt2rebNm3dZdU+ePFlZWVn2x5EjRy5rfwAA4Dqces7So48+qvvuu890Tnh4uHbt2qVffvml2Lbjx48XWzm66OJHapmZmQ7nIR07dsy+z9q1a/XDDz+oVq1aDvv269dPHTp00Pr160s8ttVqldVqNa0bAABUDU4NS/7+/vL397/kvDZt2igrK0tbtmzRbbfdJknavHmzsrKy1LZt2xL3iYiIUFBQkJKSktSyZUtJUl5enpKTkzVr1ixJ0qRJk/Tggw867NesWTO99NJLuvPOO6+kNQAAUEW4xNVwTZo0Ubdu3TRixAj94x//kCT97W9/U69evRyuhGvcuLESEhLUt29fWSwWxcfHa+bMmWrYsKEaNmyomTNnysfHR4MGDZL02+pTSSd1169fXxEREdemOQAAUKm5RFiSpHfffVejR4+2X93Wu3dvJSYmOszZt2+fsrKy7M8nTJig8+fP65FHHtGpU6fUunVrrV69Wr6+vte0dgAA4LoshmEYzi7C1WVnZ8tmsykrK0s1a9Z0djkAAKAMyvr+7RK3DgAAAHAWwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJwhIAAIAJd2cXUBUYhiFJys7OdnIlAACgrC6+b198Hy8NYakC5OTkSJJCQ0OdXAkAALhcOTk5stlspW63GJeKU7ikoqIiHT16VL6+vrJYLBV23OzsbIWGhurIkSOqWbNmhR23Mrveer7e+pXo+Xro+XrrV7r+eq4q/RqGoZycHIWEhKhatdLPTGJlqQJUq1ZNN9xww1U7fs2aNV36L2N5XG89X2/9SvR8Pbje+pWuv56rQr9mK0oXcYI3AACACcISAACACcJSJWa1WjVt2jRZrVZnl3LNXG89X2/9SvR8Pbje+pWuv56vt345wRsAAMAEK0sAAAAmCEsAAAAmCEsAAAAmCEsAAAAmCEuV2Pz58xURESEvLy9FRUVpw4YNzi6pQiQkJOjWW2+Vr6+vAgIC1KdPH+3bt89hjmEYmj59ukJCQuTt7a2OHTtqz549Tqq4YiUkJMhisSg+Pt4+VhX7/fnnnzV48GD5+fnJx8dHt9xyi7Zt22bfXtV6Ligo0JNPPqmIiAh5e3urQYMGmjFjhoqKiuxzXLnnr776SnfeeadCQkJksVj00UcfOWwvS2+5ubl67LHH5O/vr+rVq6t379766aefrmEXl8es5/z8fE2cOFHNmjVT9erVFRISoiFDhujo0aMOx3Clni/1O/69hx56SBaLRfPmzXMYd6V+LwdhqZJaunSp4uPjNXXqVKWlpalDhw7q3r27Dh8+7OzSrlhycrJGjRqlTZs2KSkpSQUFBYqNjdXZs2ftc2bPnq25c+cqMTFRqampCgoKUpcuXezfw+eqUlNT9frrr6t58+YO41Wt31OnTqldu3by8PDQ559/rr1792rOnDmqVauWfU5V63nWrFlauHChEhMTlZ6ertmzZ+uFF17Qq6++ap/jyj2fPXtWLVq0UGJiYonby9JbfHy8VqxYoSVLlujrr7/WmTNn1KtXLxUWFl6rNi6LWc/nzp3T9u3b9dRTT2n79u1avny59u/fr969ezvMc6WeL/U7vuijjz7S5s2bFRISUmybK/V7WQxUSrfddpsxcuRIh7HGjRsbkyZNclJFV8+xY8cMSUZycrJhGIZRVFRkBAUFGc8//7x9zoULFwybzWYsXLjQWWVesZycHKNhw4ZGUlKSERMTY4wZM8YwjKrZ78SJE4327duXur0q9tyzZ09j+PDhDmN33323MXjwYMMwqlbPkowVK1bYn5elt9OnTxseHh7GkiVL7HN+/vlno1q1asaqVauuWe3l9ceeS7JlyxZDknHo0CHDMFy759L6/emnn4x69eoZ3377rREWFma89NJL9m2u3O+lsLJUCeXl5Wnbtm2KjY11GI+NjdXGjRudVNXVk5WVJUmqU6eOJOnAgQPKzMx06N9qtSomJsal+x81apR69uypO+64w2G8Kva7cuVKRUdH695771VAQIBatmypN954w769Kvbcvn17ffnll9q/f78kaefOnfr666/Vo0cPSVWz54vK0tu2bduUn5/vMCckJERNmzZ1+f4vysrKksVisa+gVrWei4qKFBcXpyeeeEI333xzse1Vrd/f44t0K6ETJ06osLBQgYGBDuOBgYHKzMx0UlVXh2EYGjdunNq3b6+mTZtKkr3Hkvo/dOjQNa+xIixZskTbt29XampqsW1Vsd8ff/xRCxYs0Lhx4zRlyhRt2bJFo0ePltVq1ZAhQ6pkzxMnTlRWVpYaN24sNzc3FRYW6u9//7sGDhwoqWr+ni8qS2+ZmZny9PRU7dq1i82pCv+uXbhwQZMmTdKgQYPsXyxb1XqeNWuW3N3dNXr06BK3V7V+f4+wVIlZLBaH54ZhFBtzdY8++qh27dqlr7/+uti2qtL/kSNHNGbMGK1evVpeXl6lzqsq/Uq//RdodHS0Zs6cKUlq2bKl9uzZowULFmjIkCH2eVWp56VLl+qdd97Re++9p5tvvlk7duxQfHy8QkJCNHToUPu8qtTzH5Wnt6rQf35+vu677z4VFRVp/vz5l5zvij1v27ZNL7/8srZv337Ztbtiv3/Ex3CVkL+/v9zc3Iol8WPHjhX7LzdX9thjj2nlypVat26dbrjhBvt4UFCQJFWZ/rdt26Zjx44pKipK7u7ucnd3V3Jysl555RW5u7vbe6oq/UpScHCwIiMjHcaaNGliv0Chqv2OJemJJ57QpEmTdN9996lZs2aKi4vT2LFjlZCQIKlq9nxRWXoLCgpSXl6eTp06VeocV5Sfn6/+/fvrwIEDSkpKsq8qSVWr5w0bNujYsWOqX7++/d+xQ4cO6fHHH1d4eLikqtXvHxGWKiFPT09FRUUpKSnJYTwpKUlt27Z1UlUVxzAMPfroo1q+fLnWrl2riIgIh+0REREKCgpy6D8vL0/Jycku2f/tt9+u3bt3a8eOHfZHdHS07r//fu3YsUMNGjSoUv1KUrt27YrdDmL//v0KCwuTVPV+x9JvV0dVq+b4T6qbm5v91gFVseeLytJbVFSUPDw8HOZkZGTo22+/ddn+Lwal77//XmvWrJGfn5/D9qrUc1xcnHbt2uXw71hISIieeOIJffHFF5KqVr/FOOnEclzCkiVLDA8PD2PRokXG3r17jfj4eKN69erGwYMHnV3aFXv44YcNm81mrF+/3sjIyLA/zp07Z5/z/PPPGzabzVi+fLmxe/duY+DAgUZwcLCRnZ3txMorzu+vhjOMqtfvli1bDHd3d+Pvf/+78f333xvvvvuu4ePjY7zzzjv2OVWt56FDhxr16tUzPvnkE+PAgQPG8uXLDX9/f2PChAn2Oa7cc05OjpGWlmakpaUZkoy5c+caaWlp9iu/ytLbyJEjjRtuuMFYs2aNsX37dqNz585GixYtjIKCAme1Zcqs5/z8fKN3797GDTfcYOzYscPh37Lc3Fz7MVyp50v9jv/oj1fDGYZr9Xs5CEuV2GuvvWaEhYUZnp6eRqtWreyX1rs6SSU+3nrrLfucoqIiY9q0aUZQUJBhtVqNv/zlL8bu3budV3QF+2NYqor9fvzxx0bTpk0Nq9VqNG7c2Hj99dcdtle1nrOzs40xY8YY9evXN7y8vIwGDRoYU6dOdXjjdOWe161bV+L/b4cOHWoYRtl6O3/+vPHoo48aderUMby9vY1evXoZhw8fdkI3ZWPW84EDB0r9t2zdunX2Y7hSz5f6Hf9RSWHJlfq9HBbDMIxrsYIFAADgijhnCQAAwARhCQAAwARhCQAAwARhCQAAwARhCQAAwARhCQAAwARhCQAAwARhCQCugvXr18tisej06dPOLgXAFSIsAQAAmCAsAQAAmCAsAaiSDMPQ7Nmz1aBBA3l7e6tFixb68MMPJf3/R2SffvqpWrRoIS8vL7Vu3Vq7d+92OMayZct08803y2q1Kjw8XHPmzHHYnpubqwkTJig0NFRWq1UNGzbUokWLHOZs27ZN0dHR8vHxUdu2bbVv376r2ziACkdYAlAlPfnkk3rrrbe0YMEC7dmzR2PHjtXgwYOVnJxsn/PEE0/oxRdfVGpqqgICAtS7d2/l5+dL+i3k9O/fX/fdd592796t6dOn66mnntLixYvt+w8ZMkRLlizRK6+8ovT0dC1cuFA1atRwqGPq1KmaM2eOtm7dKnd3dw0fPvya9A+g4vBFugCqnLNnz8rf319r165VmzZt7OMPPvigzp07p7/97W/q1KmTlixZogEDBkiSTp48qRtuuEGLFy9W//79df/99+v48eNavXq1ff8JEybo008/1Z49e7R//341atRISUlJuuOOO4rVsH79enXq1Elr1qzR7bffLkn67LPP1LNnT50/f15eXl5X+acAoKKwsgSgytm7d68uXLigLl26qEaNGvbH22+/rR9++ME+7/dBqk6dOmrUqJHS09MlSenp6WrXrp3Dcdu1a6fvv/9ehYWF2rFjh9zc3BQTE2NaS/Pmze1/Dg4OliQdO3bsinsEcO24O7sAAKhoRUVFkqRPP/1U9erVc9hmtVodAtMfWSwWSb+d83Txzxf9fiHe29u7TLV4eHgUO/bF+gC4BlaWAFQ5kZGRslqtOnz4sG688UaHR2hoqH3epk2b7H8+deqU9u/fr8aNG9uP8fXXXzscd+PGjbrpppvk5uamZs2aqaioyOEcKABVEytLAKocX19fjR8/XmPHjlVRUZHat2+v7Oxsbdy4UTVq1FBYWJgkacaMGfLz81NgYKCmTp0qf39/9enTR5L0+OOP69Zbb9Wzzz6rAQMGKCUlRYmJiZo/f74kKTw8XEOHDtXw4cP1yiuvqEWLFjp06JCOHTum/v37O6t1AFcBYQlAlfTss88qICBACQkJ+vHHH1WrVi21atVKU6ZMsX8M9vzzz2vMmDH6/vvv1aJFC61cuVKenp6SpFatWuk///mPnn76aT377LMKDg7WjBkzNGzYMPtrLFiwQFOmTNEjjzyiX3/9VfXr19eUKVOc0S6Aq4ir4QBcdy5eqXbq1CnVqlXL2eUAqOQ4ZwkAAMAEYQkAAMAEH8MBAACYYGUJAADABGEJAADABGEJAADABGEJAADABGEJAADABGEJAADABGEJAADABGEJAADABGEJAADAxP8BicOZJdgVFs8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15122b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.913654e-16</td>\n",
       "      <td>-1.875504e-14</td>\n",
       "      <td>2.570219e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.276462e+00</td>\n",
       "      <td>-4.266288e+00</td>\n",
       "      <td>-3.536594e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.392292e-01</td>\n",
       "      <td>-6.706510e-01</td>\n",
       "      <td>-6.796337e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.566605e-02</td>\n",
       "      <td>-6.227861e-02</td>\n",
       "      <td>2.277844e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.051309e-01</td>\n",
       "      <td>5.772924e-01</td>\n",
       "      <td>7.916582e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.266234e+00</td>\n",
       "      <td>3.275970e+00</td>\n",
       "      <td>1.528011e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2\n",
       "count  1.503900e+04  1.503900e+04  1.503900e+04\n",
       "mean   4.913654e-16 -1.875504e-14  2.570219e-16\n",
       "std    1.000033e+00  1.000033e+00  1.000033e+00\n",
       "min   -2.276462e+00 -4.266288e+00 -3.536594e+00\n",
       "25%   -8.392292e-01 -6.706510e-01 -6.796337e-01\n",
       "50%    5.566605e-02 -6.227861e-02  2.277844e-01\n",
       "75%    8.051309e-01  5.772924e-01  7.916582e-01\n",
       "max    2.266234e+00  3.275970e+00  1.528011e+00"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = StandardScaler()\n",
    "a.fit(x)\n",
    "X_standardized = a.transform(x)\n",
    "pd.DataFrame(X_standardized).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "089d2cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=3, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\\\n",
    "    \n",
    "    adam=Adam(lr=0.01)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5347ebf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 1/5; 1/9] END .......batch_size=10, epochs=10;, score=nan total time=   0.0s\n",
      "[CV 2/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 2/5; 1/9] END .......batch_size=10, epochs=10;, score=nan total time=   0.0s\n",
      "[CV 3/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 3/5; 1/9] END .......batch_size=10, epochs=10;, score=nan total time=   0.0s\n",
      "[CV 4/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 4/5; 1/9] END .......batch_size=10, epochs=10;, score=nan total time=   0.0s\n",
      "[CV 5/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 5/5; 1/9] END .......batch_size=10, epochs=10;, score=nan total time=   0.0s\n",
      "[CV 1/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 1/5; 2/9] END .......batch_size=10, epochs=50;, score=nan total time=   0.0s\n",
      "[CV 2/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 2/5; 2/9] END .......batch_size=10, epochs=50;, score=nan total time=   0.0s\n",
      "[CV 3/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 3/5; 2/9] END .......batch_size=10, epochs=50;, score=nan total time=   0.0s\n",
      "[CV 4/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 4/5; 2/9] END .......batch_size=10, epochs=50;, score=nan total time=   0.0s\n",
      "[CV 5/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 5/5; 2/9] END .......batch_size=10, epochs=50;, score=nan total time=   0.0s\n",
      "[CV 1/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 1/5; 3/9] END ......batch_size=10, epochs=100;, score=nan total time=   0.0s\n",
      "[CV 2/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 2/5; 3/9] END ......batch_size=10, epochs=100;, score=nan total time=   0.0s\n",
      "[CV 3/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 3/5; 3/9] END ......batch_size=10, epochs=100;, score=nan total time=   0.0s\n",
      "[CV 4/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 4/5; 3/9] END ......batch_size=10, epochs=100;, score=nan total time=   0.0s\n",
      "[CV 5/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 5/5; 3/9] END ......batch_size=10, epochs=100;, score=nan total time=   0.0s\n",
      "[CV 1/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 1/5; 4/9] END .......batch_size=20, epochs=10;, score=nan total time=   0.0s\n",
      "[CV 2/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 2/5; 4/9] END .......batch_size=20, epochs=10;, score=nan total time=   0.0s\n",
      "[CV 3/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 3/5; 4/9] END .......batch_size=20, epochs=10;, score=nan total time=   0.0s\n",
      "[CV 4/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 4/5; 4/9] END .......batch_size=20, epochs=10;, score=nan total time=   0.0s\n",
      "[CV 5/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 5/5; 4/9] END .......batch_size=20, epochs=10;, score=nan total time=   0.0s\n",
      "[CV 1/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 1/5; 5/9] END .......batch_size=20, epochs=50;, score=nan total time=   0.0s\n",
      "[CV 2/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 2/5; 5/9] END .......batch_size=20, epochs=50;, score=nan total time=   0.0s\n",
      "[CV 3/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 3/5; 5/9] END .......batch_size=20, epochs=50;, score=nan total time=   0.0s\n",
      "[CV 4/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 4/5; 5/9] END .......batch_size=20, epochs=50;, score=nan total time=   0.0s\n",
      "[CV 5/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 5/5; 5/9] END .......batch_size=20, epochs=50;, score=nan total time=   0.0s\n",
      "[CV 1/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 1/5; 6/9] END ......batch_size=20, epochs=100;, score=nan total time=   0.0s\n",
      "[CV 2/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 2/5; 6/9] END ......batch_size=20, epochs=100;, score=nan total time=   0.0s\n",
      "[CV 3/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 3/5; 6/9] END ......batch_size=20, epochs=100;, score=nan total time=   0.0s\n",
      "[CV 4/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 4/5; 6/9] END ......batch_size=20, epochs=100;, score=nan total time=   0.0s\n",
      "[CV 5/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 5/5; 6/9] END ......batch_size=20, epochs=100;, score=nan total time=   0.0s\n",
      "[CV 1/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 1/5; 7/9] END .......batch_size=40, epochs=10;, score=nan total time=   0.0s\n",
      "[CV 2/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 2/5; 7/9] END .......batch_size=40, epochs=10;, score=nan total time=   0.0s\n",
      "[CV 3/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 3/5; 7/9] END .......batch_size=40, epochs=10;, score=nan total time=   0.0s\n",
      "[CV 4/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 4/5; 7/9] END .......batch_size=40, epochs=10;, score=nan total time=   0.0s\n",
      "[CV 5/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 5/5; 7/9] END .......batch_size=40, epochs=10;, score=nan total time=   0.0s\n",
      "[CV 1/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 1/5; 8/9] END .......batch_size=40, epochs=50;, score=nan total time=   0.0s\n",
      "[CV 2/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 2/5; 8/9] END .......batch_size=40, epochs=50;, score=nan total time=   0.0s\n",
      "[CV 3/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 3/5; 8/9] END .......batch_size=40, epochs=50;, score=nan total time=   0.0s\n",
      "[CV 4/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 4/5; 8/9] END .......batch_size=40, epochs=50;, score=nan total time=   0.0s\n",
      "[CV 5/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 5/5; 8/9] END .......batch_size=40, epochs=50;, score=nan total time=   0.0s\n",
      "[CV 1/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 1/5; 9/9] END ......batch_size=40, epochs=100;, score=nan total time=   0.0s\n",
      "[CV 2/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 2/5; 9/9] END ......batch_size=40, epochs=100;, score=nan total time=   0.0s\n",
      "[CV 3/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 3/5; 9/9] END ......batch_size=40, epochs=100;, score=nan total time=   0.0s\n",
      "[CV 4/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 4/5; 9/9] END ......batch_size=40, epochs=100;, score=nan total time=   0.0s\n",
      "[CV 5/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 5/5; 9/9] END ......batch_size=40, epochs=100;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 45 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n45 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1491, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 760, in fit\n    self._fit(\n  File \"C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 915, in _fit\n    X, y = self._initialize(X, y)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 845, in _initialize\n    self.target_encoder_ = self.target_encoder.fit(y)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\scikeras\\utils\\transformers.py\", line 175, in fit\n    raise ValueError(\nValueError: Unknown label type: continuous.\n\nTo implement support, subclass KerasClassifier and override ``target_encoder`` with a transformer that supports this label type.\n\nFor information on sklearn target types, see: * https://scikit-learn.org/stable/modules/generated/sklearn.utils.multiclass.type_of_target.html * https://scikit-learn.org/stable/modules/multiclass.html\n\nFor information on the SciKeras data transformation interface, see: * https://www.adriangb.com/scikeras/stable/advanced.html#data-transformers\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Build and fit the GridSearchCV\u001b[39;00m\n\u001b[0;32m     11\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator \u001b[38;5;241m=\u001b[39m model,param_grid \u001b[38;5;241m=\u001b[39m param_grid,cv \u001b[38;5;241m=\u001b[39m KFold(),verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m grid_result \u001b[38;5;241m=\u001b[39m grid\u001b[38;5;241m.\u001b[39mfit(X_standardized,y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    870\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    873\u001b[0m     )\n\u001b[1;32m--> 875\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_score)\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    408\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    412\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m     )\n\u001b[1;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    417\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    419\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    424\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 45 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n45 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1491, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 760, in fit\n    self._fit(\n  File \"C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 915, in _fit\n    X, y = self._initialize(X, y)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\scikeras\\wrappers.py\", line 845, in _initialize\n    self.target_encoder_ = self.target_encoder.fit(y)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\scikeras\\utils\\transformers.py\", line 175, in fit\n    raise ValueError(\nValueError: Unknown label type: continuous.\n\nTo implement support, subclass KerasClassifier and override ``target_encoder`` with a transformer that supports this label type.\n\nFor information on sklearn target types, see: * https://scikit-learn.org/stable/modules/generated/sklearn.utils.multiclass.type_of_target.html * https://scikit-learn.org/stable/modules/multiclass.html\n\nFor information on the SciKeras data transformation interface, see: * https://www.adriangb.com/scikeras/stable/advanced.html#data-transformers\n"
     ]
    }
   ],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from sklearn.model_selection import GridSearchCV,KFold\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0)\n",
    "# Define the grid search parameters\n",
    "batch_size = [10,20,40]\n",
    "epochs = [10,50,100]\n",
    "# Make a dictionary of the grid search parameters\n",
    "param_grid = dict(batch_size = batch_size,epochs = epochs)\n",
    "# Build and fit the GridSearchCV\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grid,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ba7ee37",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest : \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, using \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(grid_result\u001b[38;5;241m.\u001b[39mbest_score_,grid_result\u001b[38;5;241m.\u001b[39mbest_params_))\n\u001b[0;32m      2\u001b[0m means \u001b[38;5;241m=\u001b[39m grid_result\u001b[38;5;241m.\u001b[39mcv_results_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_score\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m stds \u001b[38;5;241m=\u001b[39m grid_result\u001b[38;5;241m.\u001b[39mcv_results_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd_test_score\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grid_result' is not defined"
     ]
    }
   ],
   "source": [
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "276992ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(activation_function,init):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8,input_dim = 3,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(4,input_dim = 3,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = 0.001)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c03984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "activation_function = ['softmax','relu','tanh','linear']\n",
    "init = ['uniform','normal','zero']\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "param_grids = dict(activation_function = activation_function,init = init)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de028dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(neuron1,neuron2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron1,input_dim = 3,kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = 0.001)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bba031f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "neuron1 = [4,8,16]\n",
    "neuron2 = [2,4,8]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(neuron1 = neuron1,neuron2 = neuron2)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134f651a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0fc813",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16,input_dim = 3,kernel_initializer = 'normal',activation = 'linear'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(8,input_dim = 3,kernel_initializer = 'normal',activation = 'linear'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'linear'))\n",
    "    \n",
    "    adam = Adam(lr = 0.01) #sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98c69f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 100)\n",
    "\n",
    "# Fitting the model\n",
    "\n",
    "model.fit(X_standardized,y)\n",
    "\n",
    "# Predicting using trained model\n",
    "\n",
    "y_predict = model.predict(X_standardized)\n",
    "\n",
    "# Printing the metrics\n",
    "print(accuracy_score(y_predict.round(),y.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5f4607",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdbe984",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
